{"cells":[{"cell_type":"code","execution_count":null,"id":"32147d84","metadata":{"execution":{"iopub.execute_input":"2024-01-31T11:23:42.384430Z","iopub.status.busy":"2024-01-31T11:23:42.384052Z","iopub.status.idle":"2024-01-31T11:23:42.390067Z","shell.execute_reply":"2024-01-31T11:23:42.389080Z","shell.execute_reply.started":"2024-01-31T11:23:42.384402Z"},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","from PIL import Image\n","import rasterio\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"id":"10d349ba","metadata":{"execution":{"iopub.execute_input":"2024-01-31T11:22:14.931749Z","iopub.status.busy":"2024-01-31T11:22:14.931381Z","iopub.status.idle":"2024-01-31T11:22:14.940656Z","shell.execute_reply":"2024-01-31T11:22:14.939650Z","shell.execute_reply.started":"2024-01-31T11:22:14.931720Z"},"trusted":true},"outputs":[],"source":["# model\n","class WaterMaskModel(nn.Module):\n","    def __init__(self):\n","        super(WaterMaskModel, self).__init__()\n","        self.conv1 = nn.Conv2d(6, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.conv4 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n","        self.conv5 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n","        self.conv6 = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x.float())) \n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","        x = F.relu(self.conv4(x))\n","        x = F.relu(self.conv5(x))\n","        x = torch.sigmoid(self.conv6(x))\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"1a6188c4","metadata":{},"outputs":[],"source":["# params\n","\n","batch_size = 4\n","\n","num_epochs = 4\n","model = WaterMaskModel().to('cuda')\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","accumulation_steps = 1\n"]},{"cell_type":"code","execution_count":null,"id":"e3778137","metadata":{},"outputs":[],"source":["#DataLoader\n","class datasetloader(Dataset):\n","    def __init__(self, sar_paths, mask_paths, transform=None):\n","        self.sar_paths = sar_paths\n","        self.mask_paths = mask_paths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.sar_paths)\n","\n","    def __getitem__(self, idx):\n","        sar_path = self.sar_paths[idx]\n","\n","        # Load all bands from the image using rasterio\n","        sar_image = np.zeros((6, 512, 512), dtype=np.float32)\n","        with rasterio.open(sar_path) as src:\n","            sar_image = np.stack([src.read(band + 1) for band in range(6)])\n","\n","        if self.mask_paths is not None:\n","            mask_path = self.mask_paths[idx]\n","            if mask_path is not None:\n","                # Load mask if available\n","                mask = np.array(Image.open(mask_path))\n","            else:\n","                mask = None\n","        else:\n","            mask = None\n","\n","        return sar_image, mask\n"]},{"cell_type":"code","execution_count":null,"id":"19410f80","metadata":{"execution":{"iopub.execute_input":"2024-01-31T11:37:33.721404Z","iopub.status.busy":"2024-01-31T11:37:33.720727Z","iopub.status.idle":"2024-01-31T11:37:33.854076Z","shell.execute_reply":"2024-01-31T11:37:33.853156Z","shell.execute_reply.started":"2024-01-31T11:37:33.721370Z"},"trusted":true},"outputs":[],"source":["# set paths and load the images and masks filenames for training\n","path_SAR = \"/home/mdhia/DFC2024/DATA/Data/Track1/train/images/\"\n","path_masks = \"/home/mdhia/DFC2024/DATA/Data/Track1/train/labels/\"\n","img_files = sorted(glob.glob(os.path.join(path_SAR, '*.tif')))\n","msk_files = sorted(glob.glob(os.path.join(path_masks, '*.png')))\n","\n","print(\"Number of images =\", len(img_files))\n","print(\"Number of labels =\", len(msk_files))\n","\n","# Create a DataLoader instance for training\n","\n","data_transform = transforms.Compose([\n","    transforms.ToTensor(), \n","    transforms.Normalize(0.5, 0.5) #mean , #std #maybe should be adapted\n"," \n","])\n","dataset = datasetloader(img_files, msk_files, transform=data_transform)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","\n","\n","# Example: Iterate through the first batch\n","for sar_images, masks in dataloader:\n","    print(\"SAR Image shape:\", sar_images.shape)\n","    print(\"Mask shape:\", masks.shape)\n","    break"]},{"cell_type":"code","execution_count":null,"id":"b49d76d6","metadata":{"execution":{"iopub.execute_input":"2024-01-31T10:39:15.099712Z","iopub.status.busy":"2024-01-31T10:39:15.099034Z","iopub.status.idle":"2024-01-31T10:39:15.105283Z","shell.execute_reply":"2024-01-31T10:39:15.104372Z","shell.execute_reply.started":"2024-01-31T10:39:15.099679Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def load_single_example(image_path, mask_path):\n","    # Load the image\n","    sar_image = np.zeros((6, 512, 512), dtype=np.float32)\n","    with rasterio.open(image_path) as src:\n","        sar_image = np.stack([src.read(band + 1) for band in range(6)])\n","\n","    # Load mask if available\n","    ground_truth_mask = None\n","    if mask_path is not None:\n","        try:\n","            ground_truth_mask = np.array(Image.open(mask_path))\n","        except Exception as e:\n","            print(f\"Error loading mask: {e}\")\n","\n","    return sar_image, ground_truth_mask\n"]},{"cell_type":"markdown","id":"930311e9","metadata":{},"source":["---\n","## ONLY training "]},{"cell_type":"code","execution_count":null,"id":"e382ea3b","metadata":{"execution":{"iopub.execute_input":"2024-01-31T11:43:01.509424Z","iopub.status.busy":"2024-01-31T11:43:01.508764Z","iopub.status.idle":"2024-01-31T11:44:08.066671Z","shell.execute_reply":"2024-01-31T11:44:08.065826Z","shell.execute_reply.started":"2024-01-31T11:43:01.509392Z"},"trusted":true},"outputs":[],"source":["# training\n","\n","# store training metrics\n","losses = []\n","iterations = []\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","    for i, (sar_images, masks) in enumerate(dataloader):\n","        sar_images, masks = sar_images.to('cuda'), masks.to('cuda')\n","\n","        # forward pass\n","        outputs = model(sar_images)\n","\n","        #ground truth masks\n","        targets = masks.unsqueeze(1).float()\n","        \n","        # compute the loss\n","        loss = criterion(outputs, targets)\n","\n","        # gradients accumulation\n","        loss = loss / accumulation_steps\n","        loss.backward()\n","\n","        if (i + 1) % accumulation_steps == 0:\n","            # Perform optimization step only after accumulating gradients for accumulation_steps batches\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        total_loss += loss.item()\n","\n","        # print information every 10 iterations\n","        if (i + 1) % 10 == 0:\n","            print(f'Epoch {epoch + 1}/{num_epochs}, Batch {i + 1}/{len(dataloader)}, Loss: {loss.item()}')\n","\n","        # Store metrics for plotting\n","        iterations.append(epoch * len(dataloader) + i)\n","        losses.append(loss.item())\n","\n","    # Print average loss for the epoch\n","    average_loss = total_loss / len(dataloader)\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}')\n","\n","# Plot the training loss over iterations\n","plt.plot(iterations, losses, label='Training Loss')\n","plt.title('Training Loss Over Iterations')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"0b19067e","metadata":{"execution":{"iopub.execute_input":"2024-01-31T11:47:04.742946Z","iopub.status.busy":"2024-01-31T11:47:04.742045Z","iopub.status.idle":"2024-01-31T11:47:05.208945Z","shell.execute_reply":"2024-01-31T11:47:05.207295Z","shell.execute_reply.started":"2024-01-31T11:47:04.742912Z"},"trusted":true},"outputs":[],"source":["# Set the model to evaluation mode\n","model.eval()\n","\n","# index an image and its corresponding mask for comparison\n","example_index = 795\n","example_image_path = img_files[example_index]\n","example_mask_path = msk_files[example_index]\n","\n","# load indexed image and mask\n","sar_image, ground_truth_mask = load_single_example(example_image_path, example_mask_path)\n","\n","# convert to tensor and add batch dimension\n","sar_image = torch.from_numpy(sar_image).unsqueeze(0).to('cuda')\n","ground_truth_mask = torch.from_numpy(ground_truth_mask).unsqueeze(0).to('cuda')\n","\n","# prediction using the trained model\n","predicted_mask = model(sar_image)\n","\n","# threshold the predicted mask to have binary values\n","threshold = 0.35 # we can test and change this value\n","binary_mask = (predicted_mask > threshold).float()\n","\n","# convert the binary mask to a numpy array\n","predicted_mask_np = binary_mask.squeeze().detach().cpu().numpy()\n","\n","# Plot image, mask, predicted mask\n","plt.figure(figsize=(12, 4))\n","\n","# image\n","plt.subplot(1, 3, 1)\n","plt.imshow((sar_image.squeeze().cpu().numpy()[5]))\n","plt.title('SAR Image')\n","plt.axis('off')\n","\n","# ground truth mask\n","plt.subplot(1, 3, 2)\n","plt.imshow(ground_truth_mask.squeeze().cpu().numpy())\n","plt.title('Ground Truth Mask')\n","plt.axis('off')\n","\n","# predicted mask\n","plt.subplot(1, 3, 3)\n","plt.imshow(predicted_mask_np)\n","plt.title('Predicted Mask')\n","plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"34b9f877","metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import torch\n","import glob\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","# Specify the path to the images folder\n","image_folder = \"/home/mdhia/DFC2024/DATA/Data/Track1/val/images/\"\n","img_files = sorted(glob.glob(os.path.join(image_folder, '*.tif')))\n","\n","# Create a folder to save the predicted masks\n","output_folder = \"/home/mdhia/DFC2024/wab\"\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Iterate through all images in the folder and save the predicted masks\n","for i, image_path in enumerate(img_files):\n","    # Load the image\n","    sar_image, _ = load_single_example(image_path, None)  # Set the mask to None or use a placeholder\n","\n","    # Convert to tensor and add batch dimension\n","    sar_image = torch.from_numpy(sar_image).unsqueeze(0).to('cuda')\n","\n","    # Prediction using the trained model\n","    predicted_mask = model(sar_image)\n","\n","    # Threshold the predicted mask to have binary values\n","    threshold = 0.5  # You can test and change this value\n","    binary_mask = (predicted_mask > threshold).float()\n","\n","    # Convert the binary mask to a numpy array\n","    binary_mask_np = binary_mask.squeeze().detach().cpu().numpy().astype(np.uint8)\n","\n","    # Extract the filename without extension\n","    file_name = os.path.splitext(os.path.basename(image_path))[0]\n","\n","    # Save the generated mask with the same name as the image\n","    save_path = os.path.join(output_folder, f'{file_name}_mask.png')\n","    cv2.imwrite(save_path, binary_mask_np)\n","\n","print(\"Generated masks saved in:\", output_folder)\n"]},{"cell_type":"markdown","id":"a49b2b30","metadata":{},"source":["---\n","## Train & test"]},{"cell_type":"code","execution_count":null,"id":"59766d57","metadata":{},"outputs":[],"source":["# params\n","num_epochs = 2\n","model = WaterMaskModel().to('cuda')\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","accumulation_steps = 1"]},{"cell_type":"code","execution_count":null,"id":"a1dfa46b","metadata":{"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"234dc135","metadata":{},"outputs":[],"source":["# Lists to store training and test metrics for plotting\n","train_losses = []\n","test_losses = []\n","test_accuracies = []\n","test_f1_scores = []\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0.0\n","    for i, (sar_images, masks) in enumerate(dataloader):\n","        sar_images, masks = sar_images.to('cuda'), masks.to('cuda')\n","\n","        # Forward pass\n","        outputs = model(sar_images)\n","\n","        # Assuming you have a binary water mask ground truth\n","        targets = masks.unsqueeze(1).float()\n","        \n","        # Compute the loss\n","        loss = criterion(outputs, targets)\n","\n","        # Accumulate gradients\n","        loss = loss / accumulation_steps\n","        loss.backward()\n","\n","        if (i + 1) % accumulation_steps == 0:\n","            # Perform optimization step only after accumulating gradients for accumulation_steps batches\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        total_loss += loss.item()\n","\n","        # Print detailed information every few iterations\n","        if (i + 1) % 10 == 0:\n","            print(f'Epoch {epoch + 1}/{num_epochs}, Batch {i + 1}/{len(dataloader)}, Loss: {loss.item()}')\n","\n","    # Store training loss for plotting\n","    average_loss = total_loss / len(dataloader)\n","    train_losses.append(average_loss)\n","\n","    # Validation loop (on the test set)\n","    model.eval()\n","    total_correct = 0\n","    total_samples = 0\n","    f1_scores = []\n","    test_loss = 0.0\n","\n","    with torch.no_grad():\n","        for i, (sar_images, masks) in enumerate(dataloader_test):\n","            sar_images, masks = sar_images.to('cuda'), masks.to('cuda')\n","\n","            # Forward pass\n","            outputs = model(sar_images)\n","\n","            # Assuming you have a binary water mask ground truth\n","            targets = masks.unsqueeze(1).float()\n","\n","            # Compute accuracy\n","            predicted_labels = (outputs > 0.5).float()\n","            correct = (predicted_labels == targets).sum().item()\n","            total_correct += correct\n","            total_samples += targets.numel()\n","\n","            # Compute F1 score\n","            tp = (predicted_labels * targets).sum().item()\n","            fp = ((predicted_labels == 1) & (targets == 0)).sum().item()\n","            fn = ((predicted_labels == 0) & (targets == 1)).sum().item()\n","\n","            precision = tp / (tp + fp + 1e-8)\n","            recall = tp / (tp + fn + 1e-8)\n","            f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n","            f1_scores.append(f1)\n","\n","            # Compute test loss\n","            test_loss += criterion(outputs, targets).item()\n","\n","    # Store test loss, accuracy, and F1 score for plotting\n","    average_test_loss = test_loss / len(dataloader_test)\n","    test_losses.append(average_test_loss)\n","\n","    test_accuracy = total_correct / total_samples\n","    test_accuracies.append(test_accuracy)\n","\n","    average_f1_score = sum(f1_scores) / len(f1_scores)\n","    test_f1_scores.append(average_f1_score)\n","\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {average_loss}, Average Test Loss: {average_test_loss}, Test Accuracy: {test_accuracy * 100:.2f}%, Average F1 Score: {average_f1_score:.4f}')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"82e1cdf3","metadata":{},"outputs":[],"source":["# Plot training and test loss over epochs\n","plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n","plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n","plt.title('Training and Test Loss Over Epochs')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","# Plot test accuracy and F1 score over epochs\n","plt.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy')\n","plt.plot(range(1, num_epochs + 1), test_f1_scores, label='Test F1 Score')\n","plt.title('Test Accuracy and F1 Score Over Epochs')\n","plt.xlabel('Epoch')\n","plt.ylabel('Metric Value')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"8c6ed2ed","metadata":{},"outputs":[],"source":["# Set the model to evaluation mode\n","model.eval()\n","\n","# index an image and its corresponding mask for comparison\n","example_index = 45 \n","example_image_path = img_files[example_index]\n","example_mask_path = msk_files[example_index]\n","\n","# load indexed image and mask\n","sar_image, ground_truth_mask = load_single_example(example_image_path, example_mask_path)\n","\n","# convert to tensor and add batch dimension\n","sar_image = torch.from_numpy(sar_image).unsqueeze(0).to('cuda')\n","ground_truth_mask = torch.from_numpy(ground_truth_mask).unsqueeze(0).to('cuda')\n","\n","# prediction using the trained model\n","predicted_mask = model(sar_image)\n","\n","# threshold the predicted mask to have binary values\n","threshold = 0.4 # we can test and change this value\n","binary_mask = (predicted_mask > threshold).float()\n","\n","# convert the binary mask to a numpy array\n","predicted_mask_np = binary_mask.squeeze().detach().cpu().numpy()\n","\n","# Plot image, mask, predicted mask\n","plt.figure(figsize=(12, 4))\n","\n","# image\n","plt.subplot(1, 3, 1)\n","plt.imshow((sar_image.squeeze().cpu().numpy()[5]))\n","plt.title('SAR Image')\n","plt.axis('off')\n","\n","# ground truth mask\n","plt.subplot(1, 3, 2)\n","plt.imshow(ground_truth_mask.squeeze().cpu().numpy())\n","plt.title('Ground Truth Mask')\n","plt.axis('off')\n","\n","# predicted mask\n","plt.subplot(1, 3, 3)\n","plt.imshow(predicted_mask_np)\n","plt.title('Predicted Mask')\n","plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"b17c4ada","metadata":{},"source":["---\n","## Playground"]},{"cell_type":"code","execution_count":null,"id":"6c4b0d21","metadata":{"trusted":true},"outputs":[],"source":["\n","# Specify the path to your raster image\n","image_path = '/home/mdhia/DFC2024/DATA/subset/train/images/0.tif'\n","\n","for i in range (6):\n","    with rasterio.open(image_path) as src:\n","        bands = src.read(i+1)  # reading band\n","        metadata = src.meta\n","\n","metadata"]},{"cell_type":"code","execution_count":null,"id":"dcb62b17","metadata":{"trusted":true},"outputs":[],"source":["image_path = '/home/mdhia/DFC2024/DATA/subset/train/images/0.tif'\n","\n","bands_list = []\n","\n","# Open the raster image and read each band\n","for i in range(6):\n","    with rasterio.open(image_path) as src:\n","        band = src.read(i + 1)\n","        bands_list.append(band)\n","\n","# Stack the bands into a single NumPy array\n","sar_image = np.stack(bands_list)\n"]},{"cell_type":"code","execution_count":null,"id":"bd26d1d4","metadata":{"trusted":true},"outputs":[],"source":["with rasterio.open(image_path) as src:\n","    sar_image = np.stack([src.read(band + 1) for band in range(6)])"]},{"cell_type":"code","execution_count":null,"id":"dbc7c8e7","metadata":{"trusted":true},"outputs":[],"source":["sar_image.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mask = np.array(Image.open(\"/home/mdhia/DFC2024/DATA/subset/train/labels/0.png\"))\n","mask.shape\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4373410,"sourceId":7509220,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
